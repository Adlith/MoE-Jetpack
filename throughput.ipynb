{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/25 22:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 3407\n",
      "    GPU 0,1,2,3,4,5,6,7: NVIDIA A800 80GB PCIe\n",
      "    CUDA_HOME: /usr/local/cuda-12.1\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.66\n",
      "    GCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
      "    PyTorch: 2.1.0\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.0\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 3407\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/25 22:02:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "bgr_mean = [\n",
      "    103.53,\n",
      "    116.28,\n",
      "    123.675,\n",
      "]\n",
      "bgr_std = [\n",
      "    57.375,\n",
      "    57.12,\n",
      "    58.395,\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'softmoe',\n",
      "    ])\n",
      "data_preprocessor = dict(\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    num_classes=1000,\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    to_rgb=True)\n",
      "dataset_type = 'ImageNet'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=2, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\n",
      "default_scope = 'mmpretrain'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "model = dict(\n",
      "    add_noise=False,\n",
      "    checkpoint_path='',\n",
      "    compress_ratio=1.0,\n",
      "    drop_path_rate=0.0,\n",
      "    global_pool='token',\n",
      "    init_cfg=[\n",
      "        dict(layer='Linear', std=0.02, type='TruncNormal'),\n",
      "        dict(bias=0.0, layer='LayerNorm', type='Constant', val=1.0),\n",
      "    ],\n",
      "    loss=dict(label_smooth_val=0.1, mode='original', type='LabelSmoothLoss'),\n",
      "    model_name='vit_tiny_moe_custom',\n",
      "    moe_droprate=0.2,\n",
      "    moe_groups_dict=dict(MoE_G2=[\n",
      "        8,\n",
      "        9,\n",
      "    ], MoE_G3=[\n",
      "        10,\n",
      "        11,\n",
      "    ]),\n",
      "    noise_mult=1.0,\n",
      "    num_classes=1000,\n",
      "    num_experts=197,\n",
      "    only_phi=False,\n",
      "    phi_groups_dict=dict(phi_2=[\n",
      "        'MoE_G2',\n",
      "    ], phi_3=[\n",
      "        'MoE_G3',\n",
      "    ]),\n",
      "    pretrained=False,\n",
      "    slots_per_expert=1,\n",
      "    train_cfg=dict(augments=[\n",
      "        dict(alpha=0.8, type='Mixup'),\n",
      "        dict(alpha=1.0, type='CutMix'),\n",
      "    ]),\n",
      "    type='TimmClassifier',\n",
      "    with_cp=False)\n",
      "moe_groups_dict = dict(\n",
      "    MoE_G2=[\n",
      "        8,\n",
      "        9,\n",
      "    ], MoE_G3=[\n",
      "        10,\n",
      "        11,\n",
      "    ])\n",
      "moe_mult = 1.5\n",
      "optim_wrapper = dict(\n",
      "    accumulative_counts=2,\n",
      "    clip_grad=dict(max_norm=5.0, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=0.004,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        bias_decay_mult=0.0,\n",
      "        bypass_duplicate=True,\n",
      "        custom_keys=dict({\n",
      "            '.cls_token':\n",
      "            dict(decay_mult=0.0),\n",
      "            '.moe_layers_dict.MoE_G2.experts.bias_1':\n",
      "            dict(decay_mult=0.0, lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G2.experts.bias_2':\n",
      "            dict(decay_mult=0.0, lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G2.experts.weight_1':\n",
      "            dict(lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G2.experts.weight_2':\n",
      "            dict(lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G3.experts.bias_1':\n",
      "            dict(decay_mult=0.0, lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G3.experts.bias_2':\n",
      "            dict(decay_mult=0.0, lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G3.experts.weight_1':\n",
      "            dict(lr_mult=1.5),\n",
      "            '.moe_layers_dict.MoE_G3.experts.weight_2':\n",
      "            dict(lr_mult=1.5),\n",
      "            '.pos_embed':\n",
      "            dict(decay_mult=0.0)\n",
      "        }),\n",
      "        norm_decay_mult=0.0))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=20,\n",
      "        start_factor=0.001,\n",
      "        type='LinearLR'),\n",
      "    dict(begin=20, by_epoch=True, eta_min=1e-05, type='CosineAnnealingLR'),\n",
      "]\n",
      "phi_groups_dict = dict(\n",
      "    phi_2=[\n",
      "        'MoE_G2',\n",
      "    ], phi_3=[\n",
      "        'MoE_G3',\n",
      "    ])\n",
      "randomness = dict(deterministic=False, seed=3407)\n",
      "resume = False\n",
      "test_cfg = dict()\n",
      "test_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                backend='pillow',\n",
      "                edge='short',\n",
      "                interpolation='bicubic',\n",
      "                scale=256,\n",
      "                type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        backend='pillow',\n",
      "        edge='short',\n",
      "        interpolation='bicubic',\n",
      "        scale=256,\n",
      "        type='ResizeEdge'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=300, val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_size=256,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                backend='pillow',\n",
      "                interpolation='bicubic',\n",
      "                scale=224,\n",
      "                type='RandomResizedCrop'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                hparams=dict(\n",
      "                    interpolation='bicubic', pad_val=[\n",
      "                        104,\n",
      "                        116,\n",
      "                        124,\n",
      "                    ]),\n",
      "                magnitude_level=9,\n",
      "                magnitude_std=0.5,\n",
      "                num_policies=2,\n",
      "                policies='timm_increasing',\n",
      "                total_level=10,\n",
      "                type='RandAugment'),\n",
      "            dict(\n",
      "                erase_prob=0.25,\n",
      "                fill_color=[\n",
      "                    103.53,\n",
      "                    116.28,\n",
      "                    123.675,\n",
      "                ],\n",
      "                fill_std=[\n",
      "                    57.375,\n",
      "                    57.12,\n",
      "                    58.395,\n",
      "                ],\n",
      "                max_area_ratio=0.3333333333333333,\n",
      "                min_area_ratio=0.02,\n",
      "                mode='rand',\n",
      "                type='RandomErasing'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='train',\n",
      "        type='ImageNet'),\n",
      "    num_workers=12,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        backend='pillow',\n",
      "        interpolation='bicubic',\n",
      "        scale=224,\n",
      "        type='RandomResizedCrop'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        hparams=dict(interpolation='bicubic', pad_val=[\n",
      "            104,\n",
      "            116,\n",
      "            124,\n",
      "        ]),\n",
      "        magnitude_level=9,\n",
      "        magnitude_std=0.5,\n",
      "        num_policies=2,\n",
      "        policies='timm_increasing',\n",
      "        total_level=10,\n",
      "        type='RandAugment'),\n",
      "    dict(\n",
      "        erase_prob=0.25,\n",
      "        fill_color=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        fill_std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        max_area_ratio=0.3333333333333333,\n",
      "        min_area_ratio=0.02,\n",
      "        mode='rand',\n",
      "        type='RandomErasing'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "val_cfg = dict()\n",
      "val_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                backend='pillow',\n",
      "                edge='short',\n",
      "                interpolation='bicubic',\n",
      "                scale=256,\n",
      "                type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "    dict(type='TensorboardVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/test'\n",
      "\n",
      "03/25 22:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Because batch augmentations are enabled, the data preprocessor automatically enables the `to_onehot` option to generate one-hot format labels.\n",
      "03/25 22:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/25 22:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "cfg = Config.fromfile(\"softmoe/configs/timm/vit_tiny_moe_timm.py\")\n",
    "cfg.work_dir = './work_dirs/test'\n",
    "\n",
    "if 'runner_type' not in cfg:\n",
    "    # build the default runner\n",
    "    runner = Runner.from_cfg(cfg)\n",
    "else:\n",
    "     # build customized runner from the registry\n",
    "    # if 'runner_type' is set in the cfg\n",
    "    runner = RUNNERS.build(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_val = runner.val_dataloader\n",
    "model = runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def throughput(data_loader, model):\n",
    "    model.eval()\n",
    "\n",
    "    for data in data_loader:\n",
    "        images = torch.stack(data['inputs']).cuda()\n",
    "        batch_size = images.shape[0]\n",
    "        proced_data = model.data_preprocessor(data)\n",
    "        for i in range(50):\n",
    "            model(proced_data['inputs'])\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"throughput averaged with 30 times\")\n",
    "        tic1 = time.time()\n",
    "        for i in range(30):\n",
    "            model(proced_data['inputs'])\n",
    "        torch.cuda.synchronize()\n",
    "        tic2 = time.time()\n",
    "        print(f\"batch_size {batch_size} throughput {30 * batch_size / (tic2 - tic1)}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throughput averaged with 30 times\n",
      "batch_size 64 throughput 1538.4231526173237\n"
     ]
    }
   ],
   "source": [
    "throughput(data_loader_val, model)  # batch_size 64 throughput 2044.938957036053 197*4moe:1572.249532946206 128*4moe:1723.6773518977318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
